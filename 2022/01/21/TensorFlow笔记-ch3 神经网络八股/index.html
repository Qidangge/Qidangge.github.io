<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>TensorFlow笔记-ch3 神经网络八股 | Qidangge的小小世界</title><meta name="keywords" content="机器学习,TensorFlow"><meta name="author" content="Qidangge"><meta name="copyright" content="Qidangge"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本章内容主要为神经网络基于keras的使用。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow笔记-ch3 神经网络八股">
<meta property="og:url" content="https://qidangge.github.io/2022/01/21/TensorFlow%E7%AC%94%E8%AE%B0-ch3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/index.html">
<meta property="og:site_name" content="Qidangge的小小世界">
<meta property="og:description" content="本章内容主要为神经网络基于keras的使用。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg">
<meta property="article:published_time" content="2022-01-21T10:51:56.721Z">
<meta property="article:modified_time" content="2022-04-04T13:27:17.587Z">
<meta property="article:author" content="Qidangge">
<meta property="article:tag" content="机器学习">
<meta property="article:tag" content="TensorFlow">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://qidangge.github.io/2022/01/21/TensorFlow%E7%AC%94%E8%AE%B0-ch3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":200},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: Qidangge","link":"链接: ","source":"来源: Qidangge的小小世界","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'TensorFlow笔记-ch3 神经网络八股',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-04-04 21:27:17'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/css/custom.css"><meta name="generator" content="Hexo 5.4.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/./img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">66</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">73</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">Qidangge的小小世界</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 链接</span><i class="fas fa-chevron-down expand hide"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">TensorFlow笔记-ch3 神经网络八股</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-01-21T10:51:56.721Z" title="发表于 2022-01-21 18:51:56">2022-01-21</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-04-04T13:27:17.587Z" title="更新于 2022-04-04 21:27:17">2022-04-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/TensorFlow%E7%AC%94%E8%AE%B0/">TensorFlow笔记</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">3.4k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>12分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="TensorFlow笔记-ch3 神经网络八股"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="tf-keras-搭建网络八股"><a href="#tf-keras-搭建网络八股" class="headerlink" title="tf.keras 搭建网络八股"></a>tf.keras 搭建网络八股</h1><h2 id="keras介绍"><a href="#keras介绍" class="headerlink" title="keras介绍"></a>keras介绍</h2><blockquote>
<p>tf.keras 是 tensorflow2 引入的<strong>高封装度的框架</strong>，可以用于快速搭建神经网络模型，keras 为支持快速实验而生，能够把想法迅速转换为结果，是深度学习框架之中最终易上手的一个，它提供了一致而简洁的 API，能够极大地减少一般应用下的工作量，提高代码地封装程度和复用性。</p>
</blockquote>
<p>深度学习编程框架中的 API 众多，就算是从业很久的算法工程师也不可能记住所有的 API。由于本课程时间有限，只覆盖了 tensorflow2 系列中的<strong>最常用的几个 API</strong>，仍然还有很多需要在今后的实践中继续学习，这时我们就需要参考tensorflow 的官方文档，通过<strong>阅读源码和注释</strong>的方法学习 API。<br>通常有两种方法，以下将分别介绍:</p>
<blockquote>
<p>第一种方法： pycharm 集成开发环境中查看框架源码</p>
</blockquote>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887389.png" alt="Pycharm"></p>
<p>如上图，将鼠标放置在函数上按住 Ctrl 键，会显示函数的基本信息，包括封装函数的类，函数入口参数，函数功能等。<br>按住 Ctrl 键点击函数会跳转到函数的源代码部分，使用者可以根据源码和注释进一步了解函数的实现方法。</p>
<blockquote>
<p>在 tensorflow 官网中查询函数文档</p>
<blockquote>
<p>附上官网网址：<a target="_blank" rel="noopener" href="https://tensorflow.google.cn/api_docs/python/tf/keras/Model#fit">https://tensorflow.google.cn/api_docs/python/tf/keras/Model#fit</a></p>
</blockquote>
</blockquote>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887405.png" alt="官网查看"></p>
<p>在左侧选择想要查看的API即可。</p>
<h2 id="搭建神经网络六部法"><a href="#搭建神经网络六部法" class="headerlink" title="搭建神经网络六部法"></a>搭建神经网络六部法</h2><blockquote>
<p>六部格式，定下神经网络训练的基本框架</p>
</blockquote>
<ul>
<li>第一步：<strong>import 相关模块</strong>，如 import tensorflow as tf。</li>
<li>第二步：<strong>指定输入网络的训练集和测试集</strong>，如指定训练集的输入 x_train 和标签y_train，测试集的输入 x_test 和标签 y_test。(要使得数据格式符合神经网络的输入格式)</li>
<li>第三步：逐层<strong>搭建网络结构</strong>，<code>model = tf.keras.models.Sequential()</code></li>
<li>第四步：在<code> model.compile()</code>中配置<strong>训练方法</strong>，选择训练时使用的<strong>优化器</strong>、<strong>损失函数</strong>和最终<strong>评价指标</strong>。</li>
<li>第五步：在 <code>model.fit()</code>中执行训练过程，告知训练集和测试集的<strong>输入值</strong>和<strong>标签</strong>、每个 <strong>batch 的大小</strong>（batchsize）和<strong>数据集的迭代次数</strong>（epoch）。</li>
<li>第六步：使用 <code>model.summary()</code>打印网络结构，统计参数数目。</li>
</ul>
<h3 id="各个函数用法介绍"><a href="#各个函数用法介绍" class="headerlink" title="各个函数用法介绍"></a>各个函数用法介绍</h3><blockquote>
<p>tf.keras.models.Sequential()</p>
</blockquote>
<p>Sequential 函数是一个<strong>容器</strong>，描述了神经网络的网络结构，在 Sequential函数的输入参数中描述从输入层到输出层的网络结构。可以在其中定义激活函数、正则化等。</p>
<ul>
<li><p>拉直层：<code>tf.keras.layers.Flatten()</code><br>拉直层可以变换张量的尺寸，把输入特征拉直为一维数组，是不含计算参数的层。</p>
</li>
<li><p>全连接层：<code>tf.keras.layers.Dense</code>( 神经元个数,activation=”激活函数”,kernel_regularizer=”正则化方式”)<br>   其中：<br>activation（字符串给出）可选<code> relu</code>、<code>softmax</code>、<code>sigmoid</code>、<code>tanh</code> 等<br>kernel_regularizer 可选 <code>tf.keras.regularizers.l1()</code>、<code>tf.keras.regularizers.l2()</code></p>
</li>
<li><p>卷积层：<code>tf.keras.layers.Conv2D</code>( filter = <strong>卷积核个数</strong>, kernel_size = <strong>卷积核尺寸</strong>,strides = <strong>卷积步长</strong>,padding = “valid” or “same”)</p>
</li>
<li><p>LSTM 层：tf.keras.layers.LSTM()。</p>
</li>
</ul>
<hr>
<blockquote>
<p>Model.compile( optimizer = 优化器, loss = 损失函数, metrics = [“准确率”])</p>
</blockquote>
<p>Compile 用于配置神经网络的训练方法，告知训练时使用的<strong>优化器</strong>、<strong>损失函数</strong>和<strong>准确率评测标准</strong>。</p>
<ol>
<li>optimizer 可以是<strong>字符串形式</strong>给出的优化器名字，也可以是函数形式，使用函数形式可以设置学习率、动量和超参数。</li>
</ol>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887378.png" alt="optimizer"></p>
<p>注：前期建议使用字符串形式，后面再使用函数设置学习率。<br>       更多optimizer的调用可以去官方文档：tf.keras下的Model查看。</p>
<ol start="2">
<li>Loss 可以是字符串形式给出的损失函数的名字，也可以是函数形式。</li>
</ol>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887386.png" alt="Loss可选性"></p>
<p>注：损失函数常需要经过 softmax 等函数将输出转化为概率分布的形式。from_logits 则用来标注该损失函数是否需要转换为概率的形式，<strong>取 False 时表示转化为概率分布，取 True 时表示没有转化为概率分布</strong>，直接输出。</p>
<ol start="3">
<li>Metrics 标注网络评测指标。</li>
</ol>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887407.png" alt="Metrics可选项"></p>
<p>注：我们这里选择第三个，即y为概率分布，y_为数值。</p>
<hr>
<blockquote>
<p>model.fit()</p>
<blockquote>
<p>训练集的输入特征， 训练集的标签， batch_size, epochs,<br>validation_data = (测试集的输入特征，测试集的标签)，<br>validataion_split = 从训练集划分多少比例给测试集，<br>validation_freq = 测试的 epoch 间隔次数</p>
</blockquote>
</blockquote>
<p>fit 函数用于执行训练过程。</p>
<hr>
<blockquote>
<p>model.summary()</p>
</blockquote>
<p>summary 函数用于打印<strong>网络结构</strong>和<strong>参数统计</strong>。</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887406.png"></p>
<p>上图是 model.summary()对鸢尾花分类网络的网络结构和参数统计，对于一个输入为 4 输出为 3 的全连接网络，共有 15 个参数。</p>
<h2 id="iris-数据集代码复现"><a href="#iris-数据集代码复现" class="headerlink" title="iris 数据集代码复现"></a>iris 数据集代码复现</h2><p>先给出<strong>简化后的代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>空间，使用tf.keras后，原本上百行的代码只需要24行。究其原因，在于tf.keras将原本很复杂的底层代码封装成了一个个接口函数，而我们只需要填上对应的参数即可。</p>
<blockquote>
<p>下面我们具体分析一下上代码，将六部法套入其中：</p>
</blockquote>
<p><strong>第一步：import 相关模块：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br></pre></td></tr></table></figure>
<hr>
<p><strong>第二步：指定输入网络地训练集和测试集：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br></pre></td></tr></table></figure>
<p>其中测试集的输入特征 x_test 和标签 y_test 可以像 x_train 和 y_train 一样直接从数据集获取，也可以如上述在 fit 中按比例从训练集中划分，本例选择从训练集中划分，所以只需加载 x_train，y_train 即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br></pre></td></tr></table></figure>
<p>以上代码实现了数据集的乱序。</p>
<hr>
<p><strong>第三步：逐层搭建网络结构：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line">])</span><br></pre></td></tr></table></figure>
<p>如上所示，本例使用了<strong>单层全连接网络</strong>，第一个参数表示神经元个数，第二个参数表示网络所使用的激活函数，第三个参数表示选用的正则化方法。</p>
<p>使用 Sequential 可以快速搭建网络结构，但是如果网络包含跳连等其他复杂网络结构，Sequential 就无法表示了。这就需要使用 <strong>class</strong> 来声明网络结构。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">			  <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">							<span class="built_in">super</span>(MyModel, self).__init__()</span><br><span class="line"> 							//初始化网络结构</span><br><span class="line">			  <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">							y = self.d1(x)</span><br><span class="line">							<span class="keyword">return</span> y</span><br></pre></td></tr></table></figure>
<p>使用 <strong>class 类</strong>封装网络结构，如上所示是一个 <strong>class 模板</strong>，<code>MyModel </code>表示声明的神经网络的名字，括号中的<code>Model</code>表示创建的类需要继承 tensorflow 库中的 Model 类。类中需要定义<strong>两个函数</strong>，<code>__ init__()</code>函数为类的构造函数,用于初始化类的参数，<code>spuer(MyModel,self).__ init__()</code>这行表示<strong>初始化父类的参数</strong>。之后便可初始化网络结构,搭建出神经网络所需的各种网络结构块。<code>call()</code>函数中调用<code>__init__()</code>函数中完成初始化的网络块，实现前向传播并返回推理值。<br>使用 class 方式搭建鸢尾花网络结构的代码如下所示。</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887408.png" alt="class-鸢尾花"></p>
<p>搭建好网络结构后只需要使用 Model=MyModel()构建类的对象，就可以使用该模型了。</p>
<p>下面给出使用class类搭建鸢尾花数据集的神经网络：</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887392.png" alt="class"></p>
<p>下面给出源码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="comment">###########################################</span></span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"><span class="comment">###########################################</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> datasets</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">x_train = datasets.load_iris().data</span><br><span class="line">y_train = datasets.load_iris().target</span><br><span class="line"></span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(x_train)</span><br><span class="line">np.random.seed(<span class="number">116</span>)</span><br><span class="line">np.random.shuffle(y_train)</span><br><span class="line">tf.random.set_seed(<span class="number">116</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">##################################################</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">IrisModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(IrisModel, self).__init__()</span><br><span class="line">        self.d1 = Dense(<span class="number">3</span>, activation=<span class="string">&#x27;softmax&#x27;</span>, kernel_regularizer=tf.keras.regularizers.l2())</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        y = self.d1(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line">model = IrisModel()</span><br><span class="line"><span class="comment">#################################################</span></span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>注： 和原本的代码相比，改变的地方在代码中标出。<br>①import 中添加了 Model 模块和 Dense 层、Flatten 层。<br>②使用 class 声明网络结构，model = IrisModel()初始化模型对象。</p>
<hr>
<p><strong>第四步：在 model.compile()中配置训练方法：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=tf.keras.optimizers.SGD(lr=<span class="number">0.1</span>),</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>如上所示，本例使用 <strong>SGD 优化器</strong>，并将<strong>学习率设置为 0.1</strong> ，选择<code>SparseCategoricalCrossentrop </code>作为损失函数。由于神经网络输出使用了softmax 激活函数，使得输出是概率分布，而不是原始输出，所以需要将<br><strong>from_logits 参数设置为 False</strong>。鸢尾花数据集给的标签是 0，1，2 这样的数值，而网络前向传播的输出为 概率分布，所以 metrics 需要设置为    <code>sparse_categorical_accuracy</code>。</p>
<hr>
<p><strong>第五步：在 model.fit()中执行训练过程:</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">500</span>, validation_split=<span class="number">0.2</span>, validation_freq=<span class="number">20</span>)</span><br></pre></td></tr></table></figure>
<p>在 fit 中执行训练过程,x_train,y_train 分别表示网络的输入特征和标签，batch_size 表示一次喂入神经网络的数据量，epochs 表示数据集的迭代次数,validation_split 表示数据集中测试集的划分比例，validation_freq 表示每迭<br>代 20 次在测试集上测试一次准确率。</p>
<hr>
<p><strong>第六步：使用 model.summary()打印网络结构，统计参数数目：</strong></p>
<p><code>model.summary()</code></p>
<h1 id="实例：MNIST数据集"><a href="#实例：MNIST数据集" class="headerlink" title="实例：MNIST数据集"></a>实例：MNIST数据集</h1><blockquote>
<p>MNIST是一个入门的手写数字识别的数据集。</p>
</blockquote>
<h2 id="MNIST数据集的介绍"><a href="#MNIST数据集的介绍" class="headerlink" title="MNIST数据集的介绍"></a>MNIST数据集的介绍</h2><p>MNIST 数据集一共有 7 万张图片，是 <strong>28×28 像素</strong>的 0 到 9 <strong>手写数字数据集</strong>，其中 6 万张用于训练，1 万张用于测试。每张图片包括 <strong>784（28×28）</strong> 个像素点，使用全连接网络时可将 <strong>784 个像素点</strong>组成长度为 784 的一维数组，作为输入特征。数据集图片如下所示。</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887388.png" alt="MNIST数据集"></p>
<blockquote>
<p>数据集的导入：</p>
</blockquote>
<p>keras 函数库中提供了使用 <strong>mnist 数据集的接口</strong>，代码如下所示，可以使用load_data()直接从 mnist 中读取测试集和训练集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br></pre></td></tr></table></figure>
<p>注：这里已经导入了测试数据。</p>
<hr>
<blockquote>
<p>以二位数组的形式打印出来</p>
</blockquote>
<p><strong>使用代码</strong>：<code>print(&quot;x_train.shape:\n&quot;, x_train.shape)</code></p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887401.png" alt="二维数组"></p>
<p>上述代码将读取的x_train的第一层打印出来，是一个28x28的二维数组。<br>对比矩阵图和PIL得到的图，可以知道在MNIST数据集里是使用灰度值表示具体的数字。</p>
<p>注：在MNIST里，0为黑色，255位白色，介于二者之间的呈现不同的颜色。以数值表示颜色的深浅就是灰度值。</p>
<hr>
<blockquote>
<p>MNIST数据集其它部分的shape</p>
</blockquote>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887390.png" alt="shape"></p>
<p>这里我们可以看到，x都是三维矩阵，分别为60000和10000个图片像素矩阵。<br>而y都是一维数组，每一个表示x图片代表的正确数字，是以数值的形式给出。</p>
<hr>
<h2 id="使用六部法训练MNIST数据集"><a href="#使用六部法训练MNIST数据集" class="headerlink" title="使用六部法训练MNIST数据集"></a>使用六部法训练MNIST数据集</h2><p><strong>先来给出源码</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p><strong>运行结果</strong>：</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887391.png" alt="result"></p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887402.png" alt="六部法"></p>
<hr>
<blockquote>
<p>使用class定义模型：</p>
</blockquote>
<p>代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras.layers <span class="keyword">import</span> Dense, Flatten</span><br><span class="line"><span class="keyword">from</span> tensorflow.keras <span class="keyword">import</span> Model</span><br><span class="line"></span><br><span class="line">mnist = tf.keras.datasets.mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line">x_train, x_test = x_train / <span class="number">255.0</span>, x_test / <span class="number">255.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MnistModel</span>(<span class="params">Model</span>):</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">self</span>):</span></span><br><span class="line">        <span class="built_in">super</span>(MnistModel, self).__init__()</span><br><span class="line">        self.flatten = Flatten()</span><br><span class="line">        self.d1 = Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>)</span><br><span class="line">        self.d2 = Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        x = self.flatten(x)</span><br><span class="line">        x = self.d1(x)</span><br><span class="line">        y = self.d2(x)</span><br><span class="line">        <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = MnistModel()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">              metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line">model.summary()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>注：与源代码相比，变化的地方只是模型建立区域和开头导入的几个模块。<br><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887404.png" alt="model"></p>
<hr>
<blockquote>
<p>注意事项：</p>
</blockquote>
<p>我们这里在导入数据集后进行了归一化，也就是同除255得到[0,1]的数据，利于模型的训练。<br>同时我们在实际进行手写输入的识别时除了要进行矩阵的变换之外，还要进行归一化处理。</p>
<p>MNIST数据集的图片是黑底白字，所以实际测试时也要是这个样式。</p>
<h1 id="实践二：Fashion-mnist-数据集"><a href="#实践二：Fashion-mnist-数据集" class="headerlink" title="实践二：Fashion_mnist 数据集"></a>实践二：Fashion_mnist 数据集</h1><p>Fashion_mnist 数据集具有 mnist 近乎所有的特征，包括 60000 张训练图片和 10000 张测试图片，图片被分为十类，每张图像为 28×28 的分辨率。</p>
<p><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887403.png" alt="数据集类别"></p>
<p>图片的示例：<br><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1649074887409.png" alt="数据集图片"></p>
<p>代码实例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">fashion = tf.keras.datasets.fashion_mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = fashion.load_data()</span><br><span class="line">x_train, x_test = x_train/<span class="number">255</span>, x_test/<span class="number">255</span></span><br><span class="line"></span><br><span class="line">model = tf.keras.models.Sequential([</span><br><span class="line">    tf.keras.layers.Flatten(),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>),</span><br><span class="line">    tf.keras.layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(</span><br><span class="line">    optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=<span class="literal">False</span>),</span><br><span class="line">    metrics=[<span class="string">&#x27;sparse_categorical_accuracy&#x27;</span>]</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train, batch_size=<span class="number">32</span>, epochs=<span class="number">5</span>, validation_data=(x_test, y_test), validation_freq=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">model.summery()</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<hr>
<blockquote>
<p>写在最后：</p>
</blockquote>
<p>到此，本篇内容已经学习完毕，最重要的收获就是通过tf.keras进行神经网络的构建与训练，有了前面的基础，这里就可以直接调用API了，也可以理解调用的背后具体的过程了，对于API给定的一个个参数也知道了是什么含义。</p>
<p>这只是最简单的神经网络的学习，却是以后学习的根基，毕竟构建神经网络的六部法是不会变的，适用于以后的所有实践，只是更加细化。</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Qidangge</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://qidangge.github.io/2022/01/21/TensorFlow%E7%AC%94%E8%AE%B0-ch3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/">https://qidangge.github.io/2022/01/21/TensorFlow%E7%AC%94%E8%AE%B0-ch3%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://qidangge.github.io" target="_blank">Qidangge的小小世界</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="post-meta__tags" href="/tags/TensorFlow/">TensorFlow</a></div><div class="post_share"><div class="social-share" data-image="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/22/Python%E8%AF%BE%E7%A8%8B%E5%AD%A6%E4%B9%A0-ch3%E7%BB%84%E5%90%88%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/"><img class="prev-cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back8_compressed.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python课程学习-ch3组合数据类型</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/20/TenforFlow%E7%AC%94%E8%AE%B0--ch2%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/"><img class="next-cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">TenforFlow笔记--ch2 神经网络优化</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2022/01/17/TenforFlow%E7%AC%94%E8%AE%B0--ch1%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%AE%A1%E7%AE%97/" title="TenforFlow笔记--ch1 神经网络计算"><img class="cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back6_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-17</div><div class="title">TenforFlow笔记--ch1 神经网络计算</div></div></a></div><div><a href="/2022/01/20/TenforFlow%E7%AC%94%E8%AE%B0--ch2%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%BC%98%E5%8C%96/" title="TenforFlow笔记--ch2 神经网络优化"><img class="cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-20</div><div class="title">TenforFlow笔记--ch2 神经网络优化</div></div></a></div><div><a href="/2022/09/04/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%862--%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E7%9B%B8%E5%85%B3/" title="基础知识2--激活函数相关"><img class="cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back9_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-09-04</div><div class="title">基础知识2--激活函数相关</div></div></a></div><div><a href="/2022/01/26/TensorFlow%E7%AC%94%E8%AE%B0--ch5%20%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/" title="TensorFlow笔记--ch5 卷积神经网络"><img class="cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-26</div><div class="title">TensorFlow笔记--ch5 卷积神经网络</div></div></a></div><div><a href="/2022/01/23/TensorFlow%E7%AC%94%E8%AE%B0--ch4%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1%E6%89%A9%E5%B1%95/" title="TensorFlow笔记--ch4 神经网络八股扩展"><img class="cover" src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back5_compressed.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-01-23</div><div class="title">TensorFlow笔记--ch4 神经网络八股扩展</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/./img/avatar.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">Qidangge</div><div class="author-info__description">欢迎来访</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">66</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">73</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">29</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/Qidangge"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Qidangge" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:xxxxxx@gmail.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">记录生活与收获！</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#tf-keras-%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E5%85%AB%E8%82%A1"><span class="toc-number">1.</span> <span class="toc-text">tf.keras 搭建网络八股</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#keras%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.1.</span> <span class="toc-text">keras介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%90%AD%E5%BB%BA%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%85%AD%E9%83%A8%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">搭建神经网络六部法</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%84%E4%B8%AA%E5%87%BD%E6%95%B0%E7%94%A8%E6%B3%95%E4%BB%8B%E7%BB%8D"><span class="toc-number">1.2.1.</span> <span class="toc-text">各个函数用法介绍</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#iris-%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%A3%E7%A0%81%E5%A4%8D%E7%8E%B0"><span class="toc-number">1.3.</span> <span class="toc-text">iris 数据集代码复现</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%EF%BC%9AMNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.</span> <span class="toc-text">实例：MNIST数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.1.</span> <span class="toc-text">MNIST数据集的介绍</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E5%85%AD%E9%83%A8%E6%B3%95%E8%AE%AD%E7%BB%83MNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">2.2.</span> <span class="toc-text">使用六部法训练MNIST数据集</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%AE%9E%E8%B7%B5%E4%BA%8C%EF%BC%9AFashion-mnist-%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">3.</span> <span class="toc-text">实践二：Fashion_mnist 数据集</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2022/10/23/%E5%AF%86%E7%A0%81%E5%AD%A6-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" title="密码学-数学基础知识与代码实现"><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="密码学-数学基础知识与代码实现"/></a><div class="content"><a class="title" href="/2022/10/23/%E5%AF%86%E7%A0%81%E5%AD%A6-%E6%95%B0%E5%AD%A6%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E4%B8%8E%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" title="密码学-数学基础知识与代码实现">密码学-数学基础知识与代码实现</a><time datetime="2022-10-23T08:58:16.168Z" title="发表于 2022-10-23 16:58:16">2022-10-23</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/08/%E4%B8%8D%E5%8F%AF%E5%90%A6%E8%AE%A4%E6%80%A7%E4%BF%9D%E6%8A%A4--%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/" title="不可否认性保护--数字签名"><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back7_compressed.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="不可否认性保护--数字签名"/></a><div class="content"><a class="title" href="/2022/10/08/%E4%B8%8D%E5%8F%AF%E5%90%A6%E8%AE%A4%E6%80%A7%E4%BF%9D%E6%8A%A4--%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D/" title="不可否认性保护--数字签名">不可否认性保护--数字签名</a><time datetime="2022-10-08T03:12:35.299Z" title="发表于 2022-10-08 11:12:35">2022-10-08</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/10/07/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B4--PE%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/" title="逆向工程4--PE结构详解"><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back6_compressed.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="逆向工程4--PE结构详解"/></a><div class="content"><a class="title" href="/2022/10/07/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B4--PE%E7%BB%93%E6%9E%84%E8%AF%A6%E8%A7%A3/" title="逆向工程4--PE结构详解">逆向工程4--PE结构详解</a><time datetime="2022-10-07T04:13:14.402Z" title="发表于 2022-10-07 12:13:14">2022-10-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/24/%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A81--%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E5%A8%81%E8%83%81/" title="系统安全1--信息系统安全威胁"><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back5_compressed.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="系统安全1--信息系统安全威胁"/></a><div class="content"><a class="title" href="/2022/09/24/%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A81--%E4%BF%A1%E6%81%AF%E7%B3%BB%E7%BB%9F%E5%AE%89%E5%85%A8%E5%A8%81%E8%83%81/" title="系统安全1--信息系统安全威胁">系统安全1--信息系统安全威胁</a><time datetime="2022-09-24T07:29:37.605Z" title="发表于 2022-09-24 15:29:37">2022-09-24</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2022/09/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F1--%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/" title="操作系统1--计算机系统概论"><img src="https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back7_compressed.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="操作系统1--计算机系统概论"/></a><div class="content"><a class="title" href="/2022/09/12/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F1--%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%AE%BA/" title="操作系统1--计算机系统概论">操作系统1--计算机系统概论</a><time datetime="2022-09-12T08:01:37.097Z" title="发表于 2022-09-12 16:01:37">2022-09-12</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://images-blogs-1310566801.cos.ap-guangzhou.myqcloud.com/%E5%B0%81%E9%9D%A2/back3_compressed.jpg')"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2022 By Qidangge</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div><div class="footer_custom_text">与人同行，相约共进</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><div class="js-pjax"></div><script defer="defer" id="fluttering_ribbon" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-fluttering-ribbon.min.js"></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful = true;
POWERMODE.shake = false;
POWERMODE.mobile = false;
document.body.addEventListener('input', POWERMODE);
</script><script id="click-show-text" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-show-text.min.js" data-mobile="false" data-text="来了,就,不要,走了,！" data-fontsize="15px" data-random="false" async="async"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>